{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3bd8df2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# followed from this link:               https://www.youtube.com/watch?v=cNLPt02RwF0\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "ds = pd.read_csv('C:\\\\Users\\\\taniy\\\\OneDrive\\\\Documents\\\\proj jupyter\\\\emails.csv')\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e44a794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'spam'], dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6c743b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# droping the duplicate arrays\n",
    "ds.drop_duplicates(inplace= True)\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8fb027d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "spam    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking for missing data\n",
    "ds.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6493659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\taniy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download stopwords package\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "53c24658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Subject naturally irresistible your corporate ...\n",
       "1    Subject the stock trading gunslinger  fanny is...\n",
       "2    Subject unbelievable new homes made easy  im w...\n",
       "3    Subject 4 color printing special  request addi...\n",
       "4    Subject do not have money  get software cds fr...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_text(text):\n",
    "    #1 remove punctuation \n",
    "    #2 remove stopwords (useless words and data in natural language )\n",
    "    #3 return list of clean words\n",
    "    \n",
    "    #1\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc1 = ''.join(nopunc)\n",
    "    return nopunc1\n",
    "\n",
    "ds['text'].head(5).apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bf07fce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Subject, naturally, irresistible, corporate, ...\n",
       "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
       "2    [Subject, unbelievable, new, homes, made, easy...\n",
       "3    [Subject, 4, color, printing, special, request...\n",
       "4    [Subject, money, get, software, cds, software,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_text1(text):\n",
    "    #1 remove punctuation \n",
    "    #2 remove stopwords (useless words and data in natural language )\n",
    "    #3 return list of clean words\n",
    "    \n",
    "    #1\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    2 \n",
    "    clean_words = [word for word in nopunc.split() if word.lower()       not in stopwords.words ('english')]\n",
    " \n",
    " #3\n",
    "    return clean_words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ds['text'].head(5).apply(process_text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ea5b43",
   "metadata": {},
   "source": [
    "message4 = 'hello taniya good girl girl girl girl go good hello hello'\n",
    "message5 = 'test test test test one two taniya'\n",
    "print(message4)\n",
    "\n",
    "print()\n",
    "# convert text to matrix of token count\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow4= CountVectorizer(analyzer = process_text1).fit_transform( [[message4], [message5]])\n",
    "print (bow4)\n",
    "print\n",
    "print(bow4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f04ae743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "message_bow= CountVectorizer(analyzer = process_text1).fit_transform(ds['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7825e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# op_data =  ds.drop (columns= ['text']) \n",
    "op_data =  ds['spam'] \n",
    "X_train ,X_test, Y_train, Y_test = train_test_split(message_bow,op_data, test_size=0.2 , random_state =0 ) \n",
    "# messages_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf63b42",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b50c1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train)'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1ab0fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat and train naive bayes multinomial base for dicrete type\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "classifier = model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "50169e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "977     1\n",
      "3275    0\n",
      "4163    0\n",
      "751     1\n",
      "3244    0\n",
      "       ..\n",
      "4506    0\n",
      "1050    1\n",
      "3366    0\n",
      "2191    0\n",
      "3911    0\n",
      "Name: spam, Length: 1139, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print the predictions\n",
    "Y_predict = model.predict(X_test)\n",
    "\n",
    "print(Y_predict)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4fbc8265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       863\n",
      "           1       1.00      0.97      0.98       276\n",
      "\n",
      "    accuracy                           0.99      1139\n",
      "   macro avg       0.99      0.98      0.99      1139\n",
      "weighted avg       0.99      0.99      0.99      1139\n",
      "\n",
      "[[862   1]\n",
      " [  8 268]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(Y_predict, Y_test))\n",
    "print(confusion_matrix(Y_predict, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
